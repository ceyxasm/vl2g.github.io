<!DOCTYPE html>
<!-- saved from url=(0038)https://vl2g.github.io/projects/cofar/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="COFAR">
    <meta name="author" content="VL2G IIT J">

    <title>LOGO</title>

    <link href="./index_files/bootstrap.css" rel="stylesheet">
    <link href="./index_files/style.css" rel="stylesheet">

  </head>

  <body data-new-gr-c-s-check-loaded="14.1087.0" data-gr-ext-installed="">

    <div class="container">
      <div class="header">
        <h2 class="text"><center>Contrastive Multi-View Textual-Visual Encoding: <br> Towards One Hundred Thousand-Scale One-Shot Logo Identification</center></h2>
<h4 class="text"><center><a href="https://www.linkedin.com/in/nakulsh/">Nakul Sharma</a>, <a href="https://abhiram4572.github.io/">Abhirama Subramanyam Penamakuri</a>, <a href="https://anandmishra22.github.io/">Anand Mishra</a></center></h4>
<h4 class="text"><center>Indian Institute of Technology Jodhpur </center></h4>
<h4 class="text"><center>ICVGIP 2022</center></h4>

<h4 class="text"><center> [<a href="./index_files/78.pdf">Paper</a>]  [<a href="https://github.com/thisis-nkul/one-shot-logo_icvgip">Code</a>] [<a href="https://github.com/Abhiram4572/LogoIdent">Data</a>] </center></h4>
       </div>

 <div class="container">
      <div class="header">
      <br>
<center>
<figure class="figure"> 
    <img class="figure-img" width="75%"  src="images/goal_v3.png"> 

 </figure>
</center>
&nbsp;
&nbsp;
&nbsp;

</div>
      <div class="row">
        <h3>Abstract</h3>
        <p style="text-align: justify;">                   
          In this paper, we study the problem of identifying logos of business brands in natural scenes in an open-set one-shot setting. This problem setup is significantly more challenging than traditionally-studied ‘closed-set’ and ‘large-scale training samples per category’ logo recognition settings. We propose a novel multi-view textual-visual encoding framework that encodes text appearing in the logos as well as the graphical design of the logos to learn robust contrastive representations. These representations are jointly learned for multiple views of logos over a batch and thereby they generalize well to unseen logos. We evaluate our proposed framework for cropped logo verification, cropped logo identification, and end-to-end logo identification in natural scene tasks; and compare it against state-of-the-art methods. Further, the literature lacks a ‘very-large-scale’ collection of reference logo images that can facilitate the study of one-hundred thousand-scale logo identification. To fill this gap in the literature, we introduce Wi kidata Reference Logo Dataset (WiRLD), containing logos for 100K business brands harvested from Wikidata. Our proposed framework that achieves an area under the ROC curve of 91.3% on the QMUL-OpenLogo dataset for the verification task, outperforms state-of-the-art methods by 9.1% and 2.6% on the one-shot logo identification task on the Toplogos-10 and the FlickrLogos32 datasets, respectively. Further, we show that our method is more stable compared to other baselines even when the number of candidate logos is on a 100K scale.
	</p>
      </div>
      <div class="row">
        <h3>Highlights</h3>
     <ul> 
     <li> Proposed a contrastive multi-view encoding of visual-textual features of logos and learn more robust and generalizable features.</li>
     <li> Studied the problem of logo identification in an extremely challenging scenario when number of candidate logos is as large as 100K. </li>
     <li> Introduced a very-large-scale logo dataset, namely Wikipedia Reference Logo Dataset containing 100K reference logos.</li>
     </ul>
               
     </div>


<div class="row">
  <h3 id="datasetD">Dataset Downloads (100K logos)</h3>
  <!-- <b>Explore COFAR dataset:</b> [<a href="https://vl2g.github.io/projects/cofar/gallery/index.html">Gallery</a>]<br> -->
  <div class="row">
      <li>Dataset Images and Readme at this&nbsp;[<a href="https://github.com/Abhiram4572/LogoIdent"><i>Repository</i></a>]</li>
  </div>
</div>

<hr>

<h3><strong><span style="font-size: 14pt;">Bibtex</span></strong></h3>
<p>Please cite our work as follows:</p>
<pre><tt>@inproceedings{oneshotlogo2022,
  author    = "Sharma, Nakul and 
              Penamakuri, Abhirama S. and
              Mishra, Anand",
  title     = "Contrastive Multi-View Textual-Visual Encoding: Towards One Hundred Thousand-Scale One-Shot Logo Identification",
  booktitle = "ICVGIP",
  year      = "2022",
}</tt></pre>
     </div>

<div class="row">
<h3>Contact</h3>
  <a href="https://www.linkedin.com/in/nakulsh/"><u>Nakul Sharma</u></a> email: sharma.86@iitj.ac.in<br>     
  <a href="https://www.abhiram4572.github.io/"><u>Abhirama Subramanyam</u></a> email: penamakuri.1@iitj.ac.in<br>  
</div> 

<hr>
<h3><strong><span style="font-size: 14pt;">Acknowledgements</span></strong></h3>
Abhirama S. Penamakuri is supported by Prime Minister Research Fellowship (PMRF), Minsitry of Education, Government of India.
<br><br><br>
<!-- <hr>



            
 <!-- <div class="row">
       <h3>People</h3>
       	<a href="https://ajeetksingh.github.io/"><u>Ajeet Kumar Singh</u></a></br>
        <a href="https://anandmishra22.github.io/"><u>Anand Mishra</u></a> <br>
        <a href="#"><u>Shashank Shekhar</u></a><br>
        <a href="#"> <u>Anirban Chakraborty</u></a> <br>
        
      </div> -->


      <!-- <div class="row">
       <h3>Acknowledgements</h3>
        <p> Authors would like to thank MHRD, Govt. of India and Intel Corporation for partly supporting this work. 
        </p>
      </div> -->
      
      

    </div> <!-- /container -->


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
  




</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>
